import os
import sys
import json
import logging
import signal
import time
import asyncio
import concurrent.futures
from typing import List, Dict, Tuple, Any, Optional, Callable, Coroutine
from functools import partial

import numpy as np
import cv2
import torch
import redis
import aiohttp
from PIL import Image, ImageDraw, ImageFont

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
WORKER_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(WORKER_DIR) # 'logic' ë“± ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•´ ê²½ë¡œ ì¶”ê°€
ROOT_DIR = os.path.dirname(os.path.dirname(WORKER_DIR))
CORE_DIR = os.path.join(ROOT_DIR, 'core')
# ë² ì´ìŠ¤ ì´ë¯¸ì§€ì˜ LaMa ëª¨ë“ˆ ì‚¬ìš© (PYTHONPATH=/appì— ì´ë¯¸ í¬í•¨ë¨)
sys.path.insert(0, ROOT_DIR)

from core.config import (
    LOG_LEVEL,
    LAMA_CONFIG_PATH,
    LAMA_CHECKPOINT_PATH,
    USE_CUDA,
    USE_FP16,
    INPAINTING_BATCH_SIZE_SHORT,
    INPAINTING_BATCH_SIZE_LONG,
    PROCESSOR_TASK_QUEUE,
    MASK_PADDING_PIXELS,
    HOSTING_TASKS_QUEUE,
    SUCCESS_QUEUE,
    ERROR_QUEUE,
    CPU_WORKER_COUNT,
    TRANSLATE_TEXT_RESULT_HASH_PREFIX,
    RESIZE_TARGET_SIZE,
    FONT_PATH,
    MAX_CONCURRENT_TASKS,
    MAX_POSTPROCESS_TASKS,
    INFERENCE_QUEUE_SIZE_SHORT,
    INFERENCE_QUEUE_SIZE_LONG,
    POSTPROCESSING_QUEUE_SIZE,
    POSTPROCESS_QUEUE_TIMEOUT,
    IMAGE_DOWNLOAD_MAX_RETRIES,
    IMAGE_DOWNLOAD_RETRY_DELAY
)
from core.shm_manager import get_array_from_shm, create_shm_from_array, cleanup_shm
from core.redis_client import initialize_redis, close_redis, get_redis_client

# í†µí•©ëœ ë¡œì§ ëª¨ë“ˆë“¤ ì„í¬íŠ¸
from logic.post_processing import restore_from_padding
from logic.lama_gpu import load_model as load_lama_gpu_model, run_batch_inference
from logic.mask import filter_chinese_ocr_result, generate_mask_pure_sync
from logic.text_translate import process_and_save_translation
from logic.preprocessing import process_single_task_pure_sync
from hosting.r2hosting import R2ImageHosting

# ë¶„ë¦¬ëœ ë Œë”ë§ ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from rendering_worker.result_check import ResultChecker
from rendering_worker.rendering import RenderingProcessor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=LOG_LEVEL)
logging.getLogger('asyncio').setLevel(logging.WARNING) # asyncio ìì²´ ë¡œê·¸ëŠ” ì¤„ì´ê¸°
logger = logging.getLogger(__name__)

async def enqueue_error_result(request_id: str, image_id: str, error_message: str):
    """ì—ëŸ¬ ê²°ê³¼ë¥¼ ì—ëŸ¬ íì— ì¶”ê°€í•©ë‹ˆë‹¤."""
    try:
        redis_client = get_redis_client()
        error_data = {
            "request_id": request_id,
            "image_id": image_id,
            "error_message": error_message,
            "timestamp": time.time()
        }
        error_json = json.dumps(error_data).encode('utf-8')
        await redis_client.rpush(ERROR_QUEUE, error_json)
        logger.info(f"[{request_id}] Error result enqueued to {ERROR_QUEUE}: {error_message}")
    except Exception as e:
        logger.error(f"[{request_id}] Failed to enqueue error result: {e}", exc_info=True)

class AsyncInpaintingWorker:
    """í†µí•©ëœ ë¹„ë™ê¸° ì¸í˜ì¸íŒ… + ë Œë”ë§ ì›Œì»¤ (ThreadPool ë Œë”ë§ ì ìš©)"""
    
    def __init__(self):
        # CPU ì§‘ì•½ì  ì‘ì—…ìš© ThreadPoolExecutor (ë Œë”ë§ í¬í•¨)
        self.cpu_executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=CPU_WORKER_COUNT, 
            thread_name_prefix="cpu-worker"
        )
        
        # GPU ì‘ì—… ë™ì‹œì„± ì œì–´
        self.gpu_semaphore = asyncio.Semaphore(1)
        
        # âœ¨ ì‹ ê·œ: ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œìœ¼ë¡œ ë©”ëª¨ë¦¬ ê³¼ë¶€í•˜ ë°©ì§€
        self.concurrent_task_semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS) # ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ì‘ì—… ìˆ˜

        # âœ¨ ì‹ ê·œ: í›„ì²˜ë¦¬ ë™ì‹œì„± ì œì–´ìš© ì„¸ë§ˆí¬ì–´
        self.postprocess_semaphore = asyncio.Semaphore(MAX_POSTPROCESS_TASKS) # ë™ì‹œì— ì²˜ë¦¬í•  ìµœëŒ€ í›„ì²˜ë¦¬ ì‘ì—… ìˆ˜

        # ë‚´ë¶€ íë“¤ (ì „ì²˜ë¦¬ í ì œê±°)
        self.inference_queue_short = asyncio.Queue(maxsize=INFERENCE_QUEUE_SIZE_SHORT)
        self.inference_queue_long = asyncio.Queue(maxsize=INFERENCE_QUEUE_SIZE_LONG)
        self.postprocessing_queue = asyncio.Queue(maxsize=POSTPROCESSING_QUEUE_SIZE)
        
        # R2 í˜¸ìŠ¤íŒ… ì¸ìŠ¤í„´ìŠ¤ (ìµœì¢… ê²°ê³¼ í˜¸ìŠ¤íŒ…ìš©ë§Œ)
        self.r2_hosting = R2ImageHosting()
        
        # HTTP í´ë¼ì´ì–¸íŠ¸ ì„¸ì…˜
        self.http_session: Optional[aiohttp.ClientSession] = None
        
        # ì›Œì»¤ ìƒíƒœ
        self._running = False
        self._workers = []
        
        # ë Œë”ë§ ê´€ë ¨ ì¸ìŠ¤í„´ìŠ¤ë“¤ (ë‚˜ì¤‘ì— ì´ˆê¸°í™”)
        self.rendering_processor = None
        self.result_checker = None
        self.main_loop = None

    async def start_workers(self):
        """ì›Œì»¤ íƒœìŠ¤í¬ë“¤ ì‹œì‘ (ì˜¬ë°”ë¥¸ ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ í ìƒì„±)"""
        self._running = True
        
        # HTTP í´ë¼ì´ì–¸íŠ¸ ì„¸ì…˜ ìƒì„±
        self.http_session = aiohttp.ClientSession()

        # ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ íë“¤ê³¼ ì„¸ë§ˆí¬ì–´ ìƒì„±
        self.main_loop = asyncio.get_running_loop()
        self.gpu_semaphore = asyncio.Semaphore(1)
        self.inference_queue_short = asyncio.Queue(maxsize=INFERENCE_QUEUE_SIZE_SHORT)
        self.inference_queue_long = asyncio.Queue(maxsize=INFERENCE_QUEUE_SIZE_LONG)
        self.postprocessing_queue = asyncio.Queue(maxsize=POSTPROCESSING_QUEUE_SIZE)
        
        # ë Œë”ë§ ê´€ë ¨ ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
        self.rendering_processor = RenderingProcessor(loop=self.main_loop)
        self.result_checker = ResultChecker(
            cpu_executor=self.cpu_executor,
            rendering_processor=self.rendering_processor,
            http_session=self.http_session
        )
        
        logger.info("âœ… Queues and rendering modules created in correct event loop")
        
        # âœ¨ ë³€ê²½: ë²”ìš© ì›Œì»¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤ë‹ˆì € íƒœìŠ¤í¬ë“¤ì„ ìƒì„±
        postprocess_manager_task = asyncio.create_task(
            self._concurrent_worker(
                "postprocess-manager",
                self.postprocessing_queue,
                self._handle_postprocessing_task,
                self.postprocess_semaphore,
                get_timeout=POSTPROCESS_QUEUE_TIMEOUT
            )
        )
        
        short_task = asyncio.create_task(self._gpu_inference_worker("gpu-short", is_long=False))
        long_task = asyncio.create_task(self._gpu_inference_worker("gpu-long", is_long=True))
        
        # ì™¸ë¶€ ìš”ì²­ì„ ë°›ëŠ” Redis ë¦¬ìŠ¤ë„ˆ ì›Œì»¤ ì¶”ê°€
        redis_listener_task = asyncio.create_task(self._redis_listener_worker("redis-listener"))

        self._workers = [
            postprocess_manager_task, 
            short_task, 
            long_task, 
            redis_listener_task
        ]
        logger.info(f"ğŸš€ Started {len(self._workers)} batch processing workers, including Redis listener")

    async def stop_workers(self):
        """ëª¨ë“  ì›Œì»¤ ì •ì§€"""
        self._running = False
        
        # ëª¨ë“  ì›Œì»¤ íƒœìŠ¤í¬ ì·¨ì†Œ
        for worker in self._workers:
            worker.cancel()
        
        await asyncio.gather(*self._workers, return_exceptions=True)
        self._workers.clear()
        
        # HTTP ì„¸ì…˜ ì¢…ë£Œ
        if self.http_session:
            await self.http_session.close()
            
        # ìŠ¤ë ˆë“œí’€ ì¢…ë£Œ
        self.cpu_executor.shutdown(wait=True)
        logger.info("Stopped all workers and thread pool")

    async def run_cpu_task(self, func, *args, **kwargs):
        """CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ (GIL ìš°íšŒ)"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.cpu_executor, 
            partial(func, *args, **kwargs)
        )

    async def process_ocr_task(self, task_data: dict):
        """OCR ì‘ì—… ì²˜ë¦¬ - ì§„ì •í•œ I/O/CPU ë¶„ë¦¬. ì‘ì—… ì™„ë£Œ ì‹œ ë°˜ë“œì‹œ ì„¸ë§ˆí¬ì–´ë¥¼ í•´ì œí•©ë‹ˆë‹¤."""
        request_id = task_data.get("request_id")
        
        try:
            image_url = task_data.get("image_url")
            image_id = task_data.get("image_id")
            ocr_result = task_data.get("ocr_result")
            
            logger.info(f"[{request_id}] Starting OCR task processing")
            
            try:
                # 1. ë¨¼ì € ì¤‘êµ­ì–´ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸ (ê°€ë²¼ìš´ ì‘ì—…)
                from logic.mask import filter_chinese_ocr_result
                filtered_ocr_result = filter_chinese_ocr_result(ocr_result or [], request_id)
                
                if not filtered_ocr_result:
                    # Case 2/3: ì¤‘êµ­ì–´ í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì´ë¯¸ì§€ í¬ê¸° ì •ë¦¬ (Long/Short ëª¨ë‘ ì²˜ë¦¬)
                    is_long = task_data.get("is_long")
                    logger.info(f"[{request_id}] No Chinese text found, processing image resize (is_long={is_long})")
                    
                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    image_bytes = await self._download_image_async(image_url, request_id)
                    if image_bytes is None:
                        logger.error(f"[{request_id}] Image download failed")
                        await enqueue_error_result(request_id, image_id, "Image download failed")
                        return
                    
                    # Long/Short ëª¨ë‘ ì´ë¯¸ì§€ í¬ê¸° ì •ë¦¬ ì²˜ë¦¬
                    final_image_url = await self.run_cpu_task(
                        self._handle_no_chinese_text_sync, 
                        image_bytes, 
                        image_url,
                        request_id, 
                        image_id,
                        is_long
                    )
                    
                    if final_image_url:
                        # ìµœì¢… URLì„ í˜¸ìŠ¤íŒ… íë¡œ ì „ì†¡
                        from core.redis_client import get_redis_client
                        redis_client = get_redis_client()
                        hosting_task = {
                            "request_id": request_id,
                            "image_id": image_id,
                            "image_url": final_image_url
                        }
                        await redis_client.rpush(HOSTING_TASKS_QUEUE, json.dumps(hosting_task).encode('utf-8'))
                        logger.info(f"[{request_id}] Forwarded to hosting queue (no Chinese text, final URL: {final_image_url})")
                    else:
                        await enqueue_error_result(request_id, image_id, "Failed to process no-Chinese-text image")
                    return
                
                # 2. ì¤‘êµ­ì–´ê°€ ìˆì„ ë•Œë§Œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (I/O ì‘ì—…)
                logger.debug(f"[{request_id}] Chinese text found, starting inpainting pipeline")
                logger.debug(f"[{request_id}] Downloading image (async I/O)")
                image_bytes = await self._download_image_async(image_url, request_id)
                
                if image_bytes is None:
                    logger.error(f"[{request_id}] Image download failed")
                    await enqueue_error_result(request_id, image_id, "Image download failed")
                    return
                
                # 3. ë§ˆìŠ¤í¬ ìƒì„± + ì „ì²˜ë¦¬ (CPU ì§‘ì•½ì  - ìŠ¤ë ˆë“œí’€ì—ì„œ í•œë²ˆì— ì²˜ë¦¬)
                logger.debug(f"[{request_id}] Generating mask and preprocessing (pure CPU in thread)")
                is_long = task_data.get("is_long", False)
                processed_result = await self.run_cpu_task(
                    self._generate_mask_and_preprocess_sync, 
                    image_bytes, 
                    ocr_result, 
                    request_id,
                    image_id,
                    is_long
                )
                
                if not processed_result:
                    logger.error(f"[{request_id}] Mask generation and preprocessing failed")
                    await enqueue_error_result(request_id, image_id, "Mask generation and preprocessing failed")
                    return
                
                # 4. ë²ˆì—­ ì‘ì—… (I/O ì§‘ì•½ì  - ìˆœìˆ˜ async, ì™¸ë¶€ ëª¨ë“ˆ í˜¸ì¶œ)
                logger.debug(f"[{request_id}] Running translation (async I/O)")
                # ì´ë¯¸ ì¤‘êµ­ì–´ í•„í„°ë§ì´ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ filtered_ocr_result ì „ë‹¬
                task_data_with_filtered = task_data.copy()
                task_data_with_filtered["filtered_ocr_result"] = filtered_ocr_result
                await process_and_save_translation(task_data_with_filtered, image_url, self.result_checker)
                
                # 5. ë°”ë¡œ ì¶”ë¡  íì— ì¶”ê°€ (ë°°ì¹˜ ì²˜ë¦¬)
                is_long = processed_result.get("is_long", False)
                target_queue = self.inference_queue_long if is_long else self.inference_queue_short
                await target_queue.put(processed_result)
                logger.debug(f"[{request_id}] âœ… Added to {'long' if is_long else 'short'} inference queue")
                
            except Exception as e:
                logger.error(f"[{request_id}] Error in OCR task: {e}", exc_info=True)
                await enqueue_error_result(request_id, image_id, f"OCR task processing error: {str(e)}")
        finally:
            # âœ¨ ì‹ ê·œ: ì‘ì—…ì´ ì„±ê³µí•˜ë“  ì‹¤íŒ¨í•˜ë“ , ë°˜ë“œì‹œ ì„¸ë§ˆí¬ì–´ë¥¼ í•´ì œí•˜ì—¬ ë‹¤ë¥¸ ì‘ì—…ì´ ì‹œì‘ë  ìˆ˜ ìˆë„ë¡ í•¨
            self.concurrent_task_semaphore.release()
            logger.debug(f"[{request_id}] Task finished, semaphore released.")

    async def _download_image_async(self, image_url: str, request_id: str) -> Optional[bytes]:
        """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ìˆœìˆ˜ async I/O - ë©”ì¸ ë£¨í”„ì—ì„œ)"""
        if not self.http_session:
            logger.error(f"[{request_id}] HTTP Session is not initialized.")
            return None

        try:
            # URLì´ //ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° https: ì¶”ê°€
            if image_url.startswith('//'):
                image_url = 'https:' + image_url

            logger.debug(f"[{request_id}] Downloading from: {image_url}")
            
            # ì¬ì‹œë„ ë¡œì§
            max_retries = IMAGE_DOWNLOAD_MAX_RETRIES
            retry_delay = IMAGE_DOWNLOAD_RETRY_DELAY
            
            for attempt in range(max_retries):
                try:
                    async with self.http_session.get(image_url) as response:
                        if response.status == 420:
                            if attempt < max_retries - 1:
                                wait_time = retry_delay * (attempt + 1)
                                logger.warning(f"[{request_id}] Rate limit, waiting {wait_time}s")
                                await asyncio.sleep(wait_time)
                                continue
                        response.raise_for_status()
                        image_bytes = await response.read()
                        logger.debug(f"[{request_id}] Downloaded {len(image_bytes)} bytes")
                        return image_bytes
                            
                except aiohttp.ClientResponseError as e:
                    if e.status == 420 and attempt < max_retries - 1:
                        wait_time = retry_delay * (attempt + 1)
                        logger.warning(f"[{request_id}] Rate limit, waiting {wait_time}s")
                        await asyncio.sleep(wait_time)
                        continue
                    raise
                    
        except Exception as e:
            logger.error(f"[{request_id}] Download failed: {e}", exc_info=True)
            return None

    async def _handle_postprocessing_task(self, postprocess_task: dict):
        """ë‹¨ì¼ í›„ì²˜ë¦¬ ì‘ì—…ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ , ì™„ë£Œ ì‹œ ì„¸ë§ˆí¬ì–´ë¥¼ í•´ì œí•˜ëŠ” 'ì‹¤ë¬´' í•¸ë“¤ëŸ¬"""
        try:
            # CPU ì§‘ì•½ì  ì‘ì—…ì„ ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‹¤í–‰ (ìˆœìˆ˜ ë™ê¸°)
            restored_bgr_array = await self.run_cpu_task(self._postprocess_pure_sync, postprocess_task)
            
            # CPU ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆì„ ë•Œë§Œ ê²°ê³¼ ì €ì¥
            if restored_bgr_array is not None:
                task_data = postprocess_task["task"]
                request_id = task_data.get("request_id")
                image_id = task_data.get("image_id")
                is_long = postprocess_task["is_long"]

                logger.info(f"[{request_id}] Inpainting completed, saving to ResultChecker")
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                temp_dir = "/app/output/temp_inpainted"
                os.makedirs(temp_dir, exist_ok=True)
                temp_filename = f"{request_id}.png"
                temp_path = os.path.join(temp_dir, temp_filename)
                
                success = cv2.imwrite(temp_path, restored_bgr_array)
                if success:
                    # ResultCheckerì˜ ë‚´ë¶€ ì €ì¥ì†Œì— ì¸í˜ì¸íŒ… ê²°ê³¼ ì €ì¥
                    inpainting_data = {
                        "image_id": image_id,
                        "is_long": is_long,
                        "temp_path": temp_path
                    }
                    await self.result_checker.save_inpainting_result(request_id, inpainting_data)
                else:
                    logger.error(f"[{request_id}] Failed to save inpainted image to: {temp_path}")
                    # ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ íë¡œ ì „ì†¡
                    await enqueue_error_result(request_id, task_data.get("image_id", "N/A"), "Failed to save inpainted image")
        except Exception as e:
            request_id = postprocess_task.get("task", {}).get("request_id", "N/A")
            image_id = postprocess_task.get("task", {}).get("image_id", "N/A")
            logger.error(f"[{request_id}] Error in postprocessing handler: {e}", exc_info=True)
            await enqueue_error_result(request_id, image_id, f"Postprocessing error: {str(e)}")
        finally:
            # âœ¨ ì‹ ê·œ: ì‘ì—… ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ë°˜ë“œì‹œ ì„¸ë§ˆí¬ì–´ í•´ì œ
            self.postprocess_semaphore.release()

    def _postprocess_pure_sync(self, postprocess_task: dict) -> np.ndarray:
        """í›„ì²˜ë¦¬ ìˆœìˆ˜ ë™ê¸° í•¨ìˆ˜ (100% CPU ì‘ì—…ë§Œ)"""
        try:
            task_data = postprocess_task["task"]
            result = postprocess_task["result"]
            
            padding_info = task_data.get("padding_info")
            original_size = task_data.get("original_size")
            
            # ê²°ê³¼ë¥¼ ì›ë³¸ í¬ê¸°ë¡œ ë³µì› (CPU ì§‘ì•½ì )
            restored_result = restore_from_padding(result, padding_info, original_size)
            
            # RGB -> BGR ë³€í™˜ (CPU ì§‘ì•½ì )
            restored_result_bgr = cv2.cvtColor(restored_result, cv2.COLOR_RGB2BGR)
            
            return restored_result_bgr
            
        except Exception as e:
            request_id = postprocess_task.get("task", {}).get("request_id", "N/A")
            logger.error(f"[{request_id}] Postprocessing error in thread: {e}", exc_info=True)
            raise

    # âœ¨ ì‹ ê·œ: ë²”ìš© ë™ì‹œì„± ì›Œì»¤
    async def _concurrent_worker(
        self, 
        worker_name: str, 
        queue: asyncio.Queue, 
        handler: Callable[[Dict], Coroutine], 
        semaphore: asyncio.Semaphore,
        get_timeout: Optional[float] = None
    ):
        """
        íì—ì„œ ì‘ì—…ì„ ê°€ì ¸ì™€, ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œì„±ì„ ì œì–´í•˜ë©°, ì§€ì •ëœ í•¸ë“¤ëŸ¬ë¡œ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ”
        ë²”ìš© ì›Œì»¤ì…ë‹ˆë‹¤.
        """
        logger.info(f"Concurrent worker '{worker_name}' started for queue '{queue}'")
        while self._running:
            try:
                if get_timeout:
                    task_data = await asyncio.wait_for(queue.get(), timeout=get_timeout)
                else:
                    task_data = await queue.get()

                await semaphore.acquire()
                asyncio.create_task(handler(task_data))
                queue.task_done()

            except asyncio.TimeoutError:
                continue
            except asyncio.CancelledError:
                logger.info(f"Worker '{worker_name}' cancelled.")
                break
            except Exception as e:
                logger.error(f"Unexpected error in worker '{worker_name}': {e}", exc_info=True)
                await asyncio.sleep(1)

    # âœ¨ ì‹ ê·œ: ë©”ì¸ ë£¨í”„ì—ì„œ ë¶„ë¦¬ëœ Redis ë¦¬ìŠ¤ë„ˆ ì›Œì»¤
    async def _redis_listener_worker(self, worker_name: str):
        """Redis íì—ì„œ ì‘ì—…ì„ ì§€ì†ì ìœ¼ë¡œ ê°€ì ¸ì™€ ì²˜ë¦¬ íƒœìŠ¤í¬ë¥¼ ìƒì„±í•˜ëŠ” ì›Œì»¤"""
        logger.info(f"Worker {worker_name} started. Listening on: {PROCESSOR_TASK_QUEUE}")
        
        while self._running:
            try:
                redis_client = get_redis_client()
                
                # Redisì—ì„œ OCR ì‘ì—… ë°›ê¸°
                ocr_task_tuple = await redis_client.blpop([PROCESSOR_TASK_QUEUE], timeout=1)
                
                if ocr_task_tuple:
                    # âœ¨ ì‹ ê·œ: ìƒˆë¡œìš´ ì‘ì—…ì„ ì‹œì‘í•˜ê¸° ì „ì— ì„¸ë§ˆí¬ì–´ë¥¼ íšë“ (íšë“í•  ìˆ˜ ìˆì„ ë•Œê¹Œì§€ ëŒ€ê¸°)
                    # ì´ë¥¼ í†µí•´ ë™ì‹œì— ì‹¤í–‰ë˜ëŠ” ì‘ì—…ì˜ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.
                    await self.concurrent_task_semaphore.acquire()
                    
                    task_bytes = ocr_task_tuple[1]
                    try:
                        task_data = json.loads(task_bytes.decode('utf-8'))
                        request_id = task_data.get('request_id', 'N/A')
                        logger.debug(f"[{request_id}] Acquired semaphore, creating task.")
                        
                        # OCR ì‘ì—…ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ (fire-and-forget)
                        asyncio.create_task(self.process_ocr_task(task_data))
                        
                    except json.JSONDecodeError as e:
                        logger.error(f"Failed to decode OCR task JSON: {e}")
                        self.concurrent_task_semaphore.release()
                    except Exception as e:
                        req_id = task_data.get('request_id', 'N/A') if 'task_data' in locals() else 'N/A'
                        logger.error(f"[{req_id}] Error creating OCR task: {e}", exc_info=True)
                        self.concurrent_task_semaphore.release()
                else:
                    await asyncio.sleep(0.1)

            except asyncio.CancelledError:
                logger.info(f"Worker {worker_name} cancelled")
                break
            except (redis.exceptions.ConnectionError, redis.exceptions.TimeoutError) as e:
                logger.error(f"Redis connection error in {worker_name}: {e}")
                await asyncio.sleep(5)
            except Exception as e:
                logger.error(f"Unexpected error in {worker_name}: {e}", exc_info=True)
                await asyncio.sleep(1)

    def _handle_no_chinese_text_sync(self, image_bytes: bytes, original_url: str, request_id: str, image_id: str, is_long: bool) -> str:
        """ì¤‘êµ­ì–´ í…ìŠ¤íŠ¸ê°€ ì—†ì„ ë•Œ Long/Short ëª¨ë‘ ì´ë¯¸ì§€ í¬ê¸° ì •ë¦¬ ì²˜ë¦¬ (ìˆœìˆ˜ ë™ê¸° í•¨ìˆ˜)"""
        try:
            # 1. ì´ë¯¸ì§€ ë””ì½”ë”©
            img_array = np.frombuffer(image_bytes, dtype=np.uint8)
            img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            
            if img is None:
                logger.error(f"[{request_id}] Failed to decode image")
                return original_url
            
            # 2. rendering.pyì™€ ë™ì¼í•œ ì´ë¯¸ì§€ í¬ê¸° ì •ë¦¬ ë¡œì§
            original_h, original_w = img.shape[:2]
            
            if not is_long:
                # Short: 1024x1024 ê³ ì •
                target_h, target_w = RESIZE_TARGET_SIZE
                logger.info(f"[{request_id}] Short image: {original_w}x{original_h} â†’ {target_w}x{target_h}")
            else:
                # Long: ê°€ë¡œ 864px ê³ ì •, ì„¸ë¡œ ë¹„ìœ¨ ìœ ì§€
                target_w = 864
                scale = target_w / original_w
                target_h = int(original_h * scale)
                logger.info(f"[{request_id}] Long image: {original_w}x{original_h} â†’ {target_w}x{target_h}")
            
            # 3. ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
            resized_img = cv2.resize(img, (target_w, target_h))
            
            # 4. R2ì— ì—…ë¡œë“œ
            from datetime import datetime
            current_date = datetime.now().strftime('%Y-%m-%d')
            
            # image_idì—ì„œ productId ì¶”ì¶œ (ì²« ë²ˆì§¸ '-'ë¡œ ë¶„ë¦¬)
            if '-' in image_id:
                product_id = image_id.split('-', 1)[0]
                remaining_part = image_id.split('-', 1)[1]
            else:
                product_id = image_id
                remaining_part = ""
            
            # íŒŒì¼ëª… êµ¬ì„±: remaining_part + '-' + request_idì˜ ì²« 5ê¸€ì
            final_image_id = f"{remaining_part}-{request_id[:5]}" if remaining_part else f"{image_id}-{request_id[:5]}"
            
            upload_result = self.r2_hosting.upload_image_from_array(
                image_array=resized_img,
                image_id=final_image_id,
                sub_path=f'translated_image/{current_date}/{product_id}',
                file_ext='.jpg',
                quality=90,
                metadata={
                    "request_id": request_id,
                    "image_id": image_id,
                    "type": f"no_chinese_text_{'long' if is_long else 'short'}_resize"
                }
            )
            
            if upload_result["success"]:
                final_image_url = upload_result["url"]
                logger.info(f"[{request_id}] Image resized and uploaded: {final_image_url}")
                return final_image_url
            else:
                logger.error(f"[{request_id}] Failed to upload resized image: {upload_result.get('error')}")
                return original_url  # ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì›ë³¸ URL ë°˜í™˜
                
        except Exception as e:
            logger.error(f"[{request_id}] Error in no-Chinese-text handler: {e}", exc_info=True)
            return original_url  # ì—ëŸ¬ ì‹œ ì›ë³¸ URL ë°˜í™˜

    def _generate_mask_and_preprocess_sync(self, image_bytes: bytes, ocr_result: list, request_id: str, image_id: str, is_long: bool):
        """ë§ˆìŠ¤í¬ ìƒì„± + ì „ì²˜ë¦¬ë¥¼ í•œë²ˆì— ì²˜ë¦¬í•˜ëŠ” ìˆœìˆ˜ ë™ê¸° í•¨ìˆ˜ (CPU ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰)"""
        try:
            from logic.mask import generate_mask_pure_sync
            from logic.preprocessing import process_single_task_pure_sync
            
            # 1. ë§ˆìŠ¤í¬ ìƒì„±
            logger.debug(f"[{request_id}] Generating mask (pure CPU)")
            mask_result = generate_mask_pure_sync(image_bytes, ocr_result, request_id, image_id, is_long)
            
            if not mask_result:
                logger.error(f"[{request_id}] Mask generation failed")
                return None
            
            img_array, mask_array, preprocessing_task = mask_result
            
            # 2. ë°”ë¡œ ì „ì²˜ë¦¬ ì‹¤í–‰
            logger.debug(f"[{request_id}] Running preprocessing (pure CPU)")
            processed_task = process_single_task_pure_sync(preprocessing_task, is_long)
            
            if not processed_task:
                logger.error(f"[{request_id}] Preprocessing failed")
                return None
                
            logger.debug(f"[{request_id}] Mask generation and preprocessing completed")
            return processed_task
            
        except Exception as e:
            logger.error(f"[{request_id}] Error in mask generation and preprocessing: {e}", exc_info=True)
            return None

    async def _gpu_inference_worker(self, worker_name: str, is_long: bool):
        """GPU ì¸í¼ëŸ°ìŠ¤ ì›Œì»¤ (ë°°ì¹˜ ì²˜ë¦¬) - ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ GPU ì¶”ë¡  ì‹¤í–‰"""
        logger.info(f"GPU inference worker {worker_name} started")
        
        queue = self.inference_queue_long if is_long else self.inference_queue_short
        batch_size = INPAINTING_BATCH_SIZE_LONG if is_long else INPAINTING_BATCH_SIZE_SHORT
        
        while self._running:
            try:
                # ë°°ì¹˜ ìˆ˜ì§‘
                batch_tasks = []
                try:
                    # ì²« ë²ˆì§¸ ì‘ì—… ëŒ€ê¸°
                    task = await asyncio.wait_for(queue.get(), timeout=2.0)
                    batch_tasks.append(task)
                    
                    # ë‚˜ë¨¸ì§€ ë°°ì¹˜ ìˆ˜ì§‘
                    for _ in range(batch_size - 1):
                        try:
                            task = await asyncio.wait_for(queue.get(), timeout=0.1)
                            batch_tasks.append(task)
                        except asyncio.TimeoutError:
                            break
                            
                except asyncio.TimeoutError:
                    continue
                
                if batch_tasks:
                    logger.info(f"[{worker_name}] Processing batch of {len(batch_tasks)} tasks")
                    await self._process_gpu_batch(batch_tasks, is_long, worker_name)
                    
            except asyncio.CancelledError:
                logger.info(f"GPU worker {worker_name} cancelled")
                break
            except Exception as e:
                logger.error(f"Error in GPU worker {worker_name}: {e}", exc_info=True)
                await asyncio.sleep(1)

    async def _process_gpu_batch(self, batch_tasks: List[Dict[str, Any]], is_long: bool, worker_name: str):
        """GPU ë°°ì¹˜ ì²˜ë¦¬"""
        async with self.gpu_semaphore:  # GPU ë™ì‹œì„± ì œì–´
            try:
                batch_start_time = time.time()
                
                # ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
                images_np = []
                masks_np = []
                shm_handles = []
                
                for task in batch_tasks:
                    try:
                        request_id = task.get("request_id")
                        preprocessed_img_shm_info = task.get("preprocessed_img_shm_info")
                        preprocessed_mask_shm_info = task.get("preprocessed_mask_shm_info")

                        if not all([preprocessed_img_shm_info, preprocessed_mask_shm_info]):
                            logger.error(f"[{request_id}] Missing preprocessed data")
                            continue
                        
                        # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë¡œë“œ
                        img_array, img_shm = get_array_from_shm(preprocessed_img_shm_info)
                        shm_handles.append(img_shm)
                        
                        # ì „ì²˜ë¦¬ëœ ë§ˆìŠ¤í¬ ë¡œë“œ
                        mask_array, mask_shm = get_array_from_shm(preprocessed_mask_shm_info)
                        shm_handles.append(mask_shm)
                        
                        if img_array is None or mask_array is None:
                            logger.error(f"[{request_id}] Failed to load from SHM")
                            continue
                        
                        images_np.append(img_array)
                        masks_np.append(mask_array)
                        
                    except Exception as e:
                        logger.error(f"Error loading batch data: {e}", exc_info=True)
                        continue
                
                if not images_np:
                    logger.warning(f"[{worker_name}] No valid images in batch")
                    return
                
                # GPU ì¶”ë¡  ì‹¤í–‰
                logger.info(f"[{worker_name}] Running LaMa inference on {len(images_np)} images")
                results_np = run_batch_inference(
                    images_np=images_np,
                    masks_np=masks_np,
                    use_fp16=USE_FP16
                )
                
                # í›„ì²˜ë¦¬ë¥¼ ìœ„í•œ ì‘ì—…ë“¤ì„ íì— ì¶”ê°€
                for i, result in enumerate(results_np):
                    if i < len(batch_tasks):
                        postprocess_task = {
                            "task": batch_tasks[i],
                            "result": result,
                            "is_long": is_long
                        }
                        
                        # í›„ì²˜ë¦¬ íì— ì¶”ê°€
                        await self.postprocessing_queue.put(postprocess_task)

                # ì „ì²˜ë¦¬ëœ ê³µìœ  ë©”ëª¨ë¦¬ ì •ë¦¬
                for task in batch_tasks:
                    self._cleanup_preprocessed_shm(task)

                batch_time = time.time() - batch_start_time
                logger.info(f"[{worker_name}] Batch completed in {batch_time:.2f}s")
                    
            except Exception as e:
                logger.error(f"[{worker_name}] GPU batch error: {e}", exc_info=True)
                # GPU ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ê° ì‘ì—…ì— ëŒ€í•´ ì—ëŸ¬ íë¡œ ì „ì†¡
                for task in batch_tasks:
                    try:
                        request_id = task.get("request_id", "N/A")
                        image_id = task.get("image_id", "N/A")
                        await enqueue_error_result(request_id, image_id, f"GPU processing error: {str(e)}")
                    except Exception as eq_error:
                        logger.error(f"Failed to send GPU error to queue: {eq_error}")
            finally:
                # SHM í•¸ë“¤ ë‹«ê¸°
                for shm in shm_handles:
                    try:
                        if shm:
                            shm.close()
                    except Exception:
                        pass

    def _cleanup_preprocessed_shm(self, task: dict):
        """ì „ì²˜ë¦¬ëœ ê³µìœ  ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            for shm_key in ["preprocessed_img_shm_info", "preprocessed_mask_shm_info"]:
                shm_info = task.get(shm_key)
                if shm_info and 'shm_name' in shm_info:
                    cleanup_shm(shm_info['shm_name'])
        except Exception as e:
            logger.error(f"Error cleaning up SHM: {e}")

# ì „ì—­ ì›Œì»¤ ì¸ìŠ¤í„´ìŠ¤
async_worker = AsyncInpaintingWorker()

async def load_model():
    """LaMa ëª¨ë¸ ë¡œë“œ"""
    try:
        logger.info("Loading LaMa GPU model...")
        await load_lama_gpu_model(LAMA_CONFIG_PATH, LAMA_CHECKPOINT_PATH, USE_CUDA)
    except Exception as e:
        logger.error(f"Failed to load LaMa model: {e}", exc_info=True)
        raise

async def run_worker(stop_event: asyncio.Event):
    """ë©”ì¸ ì›Œì»¤ ë£¨í”„ (í†µí•© íŒŒì´í”„ë¼ì¸: OCR í›„ì²˜ë¦¬ + ì¸í˜ì¸íŒ… + ThreadPool ë Œë”ë§)"""
    redis_initialized = False
    
    try:
        # Redis ì´ˆê¸°í™”
        await initialize_redis()
        redis_initialized = True
        
        # LaMa ëª¨ë¸ ë¡œë“œ
        await load_model()
        
        # ë¹„ë™ê¸° ì›Œì»¤ë“¤ ì‹œì‘
        await async_worker.start_workers()
        
        logger.info(f"Complete pipeline worker started. Listening: {PROCESSOR_TASK_QUEUE}")
        logger.info("Pipeline: OCR â†’ Translation â†’ Inpainting â†’ ThreadPool Rendering â†’ Hosting")
        
        while not stop_event.is_set():
            try:
                redis_client = get_redis_client()
                
                # Redisì—ì„œ OCR ì‘ì—… ë°›ê¸°
                ocr_task_tuple = await redis_client.blpop([PROCESSOR_TASK_QUEUE], timeout=1)
                
                if ocr_task_tuple:
                    # âœ¨ ì‹ ê·œ: ìƒˆë¡œìš´ ì‘ì—…ì„ ì‹œì‘í•˜ê¸° ì „ì— ì„¸ë§ˆí¬ì–´ë¥¼ íšë“ (íšë“í•  ìˆ˜ ìˆì„ ë•Œê¹Œì§€ ëŒ€ê¸°)
                    # ì´ë¥¼ í†µí•´ ë™ì‹œì— ì‹¤í–‰ë˜ëŠ” ì‘ì—…ì˜ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.
                    await async_worker.concurrent_task_semaphore.acquire()
                    
                    task_bytes = ocr_task_tuple[1]
                    try:
                        task_data = json.loads(task_bytes.decode('utf-8'))
                        request_id = task_data.get('request_id', 'N/A')
                        logger.debug(f"[{request_id}] Acquired semaphore, creating task.")
                        
                        # OCR ì‘ì—…ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ (fire-and-forget)
                        # ì´ íƒœìŠ¤í¬ëŠ” ì™„ë£Œ ì‹œ ë°˜ë“œì‹œ ì„¸ë§ˆí¬ì–´ë¥¼ í•´ì œí•´ì•¼ í•©ë‹ˆë‹¤.
                        asyncio.create_task(async_worker.process_ocr_task(task_data))
                        
                    except json.JSONDecodeError as e:
                        logger.error(f"Failed to decode OCR task JSON: {e}")
                        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ íë¡œ ì „ì†¡
                        await enqueue_error_result("N/A", "N/A", f"JSON decode error: {str(e)}")
                        async_worker.concurrent_task_semaphore.release() # âœ¨ ì‹ ê·œ: JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œì—ë„ ì„¸ë§ˆí¬ì–´ í•´ì œ
                    except Exception as e:
                        req_id = task_data.get('request_id', 'N/A') if 'task_data' in locals() else 'N/A'
                        img_id = task_data.get('image_id', 'N/A') if 'task_data' in locals() else 'N/A'
                        logger.error(f"[{req_id}] Error processing OCR task: {e}", exc_info=True)
                        await enqueue_error_result(req_id, img_id, f"Task processing error: {str(e)}")
                        async_worker.concurrent_task_semaphore.release() # âœ¨ ì‹ ê·œ: ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì„¸ë§ˆí¬ì–´ í•´ì œ
                else:
                    # ì ì‹œ ëŒ€ê¸°
                    await asyncio.sleep(0.1)
                    
            except asyncio.CancelledError:
                logger.info("Main loop cancelled")
                break
            except (redis.exceptions.ConnectionError, redis.exceptions.TimeoutError) as e:
                logger.error(f"Redis connection error: {e}")
                await asyncio.sleep(5)
            except Exception as e:
                logger.error(f"Unexpected error in main loop: {e}", exc_info=True)
                await asyncio.sleep(1)
    
    except Exception as e:
        logger.critical(f"Critical worker error: {e}", exc_info=True)
    finally:
        logger.info("Shutting down complete pipeline worker...")
        
        await async_worker.stop_workers()
        if redis_initialized:
            await close_redis()

def main():
    """ë©”ì¸ ì§„ì…ì """
    stop_event = asyncio.Event()
    
    def shutdown_handler(sig, frame):
        logger.info(f"Signal {sig} received. Starting graceful shutdown...")
        loop = asyncio.get_event_loop()
        if loop.is_running():
            loop.call_soon_threadsafe(stop_event.set)
    
    # ì‹ í˜¸ í•¸ë“¤ëŸ¬ ë“±ë¡
    signal.signal(signal.SIGINT, shutdown_handler)
    signal.signal(signal.SIGTERM, shutdown_handler)
    
    try:
        asyncio.run(run_worker(stop_event))
    except KeyboardInterrupt:
        logger.info("KeyboardInterrupt detected. Shutting down.")
        if not stop_event.is_set():
            stop_event.set()
    
    logger.info("Complete pipeline worker shutdown complete.")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.critical(f"Critical error during worker execution: {e}", exc_info=True)
        exit(1)
