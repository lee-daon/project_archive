# Image Translate Pipeline

## 현재 성능
RTX 4050 노트북 환경에서 23장 처리 시 약 25초 소요 (첫 번째 결과 도출까지 약 6초)
*성능은 환경과 이미지 특성에 따라 달라질 수 있습니다.

## 개요

이 프로젝트는 이미지 번역 파이프라인 구현을 시도하며, 여러 단계의 이미지 처리 작업을 보다 효율적으로 처리하기 위해 Redis 큐와 워커 패턴을 활용했습니다.

## 구상 : 큐-워커 패턴

시스템은 여러 독립적인 워커(Worker)와 이들 사이의 작업을 조율하는 Redis 큐(Queue)로 구성됩니다.

1.  **API 서버:** 사용자 요청을 받아 이미지를 처리하고 초기 작업을 큐에 넣습니다.
2.  **OCR 워커:** 이미지에서 텍스트를 추출합니다.
3.  **Processor 워커:** 추출된 텍스트를 번역하고, 텍스트 영역을 지우기 위한 마스크를 생성합니다.
4.  **Preprocessing 워커:** 원본 이미지와 마스크를 받아 CPU에서 디노이징 및 크기 조정/패딩 등의 전처리를 수행합니다.
5.  **Inpainting 워커:** 전처리된 이미지와 마스크를 받아 LaMa 모델을 통해 텍스트 영역을 지웁니다.
6.  **Result Checker 워커:** 번역 결과와 Inpainting 결과가 모두 준비되었는지 확인합니다.
7.  **Rendering 워커:** Inpainting된 이미지 위에 번역된 텍스트를 렌더링하여 최종 결과 이미지를 생성합니다.

## Redis 큐 및 데이터 스키마

각 처리 단계는 Redis 큐를 통해 작업을 전달받습니다. 자세한 데이터 스키마는 `redis_queue_schema.js` 파일을 참조하십시오.

1.  **`ocr_tasks` (List):**
    *   **역할:** API 서버가 생성하고 OCR 워커가 소비합니다. 이미지 OCR 작업을 요청합니다.
    *   **주요 데이터:** `request_id`, `image_id`, `shm_info` (원본 이미지 공유 메모리 정보), `is_long`.
    *   **개선 시도:** 대용량 이미지 데이터를 직접 전달하는 대신 공유 메모리(SHM) 정보를 전달하여 네트워크 오버헤드와 직렬화/역직렬화 비용을 줄이고자 했습니다.

2.  **`processor_tasks` (List - 암시적, OCR 결과):**
    *   **역할:** OCR 워커가 생성하고 Processor 워커가 소비합니다. OCR 결과(텍스트 좌표, 내용)를 전달하여 번역 및 마스크 생성을 요청합니다.
    *   **주요 데이터:** `request_id`, `image_id`, `shm_info`, `ocr_result`.
    *   **개선 시도:** 원본 이미지 정보는 계속 SHM으로 관리하여 효율성 향상을 도모했습니다.

3.  **`inpainting_long_tasks` / `inpainting_short_tasks` (List):**
    *   **역할:** Processor 워커가 생성하고 Preprocessing 워커가 소비합니다. 이미지 전처리 작업을 요청합니다. 이미지 종류(`is_long`)에 따라 큐를 분리하여 처리 전략을 다르게 가져가려 했습니다.
    *   **주요 데이터:** `request_id`, `image_id`, `shm_info` (원본 이미지), `mask_shm_info` (마스크 이미지 공유 메모리 정보).
    *   **개선 시도:** 원본 이미지와 생성된 마스크 이미지 모두 공유 메모리 정보를 통해 전달하려 했습니다.

4.  **`lama_inference_long_tasks` / `lama_inference_short_tasks` (List - 신규):**
    *   **역할:** Preprocessing 워커가 생성하고 Inpainting 워커가 소비합니다. LaMa 모델 추론 작업을 요청합니다.
    *   **주요 데이터:** `request_id`, `image_id`, `original_size`, `padding_info`, `preprocessed_img_shm_info`, `preprocessed_mask_shm_info`, `original_shm_info`, `is_long`.
    *   **개선 시도:** 전처리된 이미지와 마스크를 공유 메모리로 전달하여 추론 과정에서의 병목을 줄이고자 했습니다.

5.  **`translate_text_result:{request_id}` (Hash):**
    *   **역할:** Processor 워커가 번역 결과를 저장하는 중간 저장소입니다.
    *   **주요 데이터:** `image_id`, `translate_result` (번역 결과 JSON), `original_shm_info`.
    *   **개선 시도:** 번역 작업과 Inpainting 작업을 분리하여 병렬 처리하고, 최종 렌더링 단계 전에 결과 취합을 용이하게 하려 했습니다.

6.  **`inpainting_result:{request_id}` (Hash):**
    *   **역할:** Inpainting 워커가 처리 결과(Inpainting된 이미지의 SHM 정보)를 저장하는 중간 저장소입니다.
    *   **주요 데이터:** `image_id`, `inpaint_shm_info`.
    *   **개선 시도:** Inpainting 작업 완료 후 결과 이미지 데이터를 직접 전달하지 않고 SHM 정보만 저장하여 효율성을 개선하려 했습니다.

7.  **`rendering_tasks` (List):**
    *   **역할:** Result Checker 워커가 생성하고 Rendering 워커가 소비합니다. 최종 이미지 렌더링 작업을 요청합니다.
    *   **주요 데이터:** `request_id`, `image_id`, `translate_data` (번역 결과 JSON), `inpaint_shm_info` (JSON), `original_shm_info` (JSON).
    *   **개선 시도:** Result Checker가 `translate_text_result` 및 `inpainting_result` 해시를 확인하여 두 결과가 모두 준비되었을 때만 렌더링 작업을 큐에 넣어, Rendering 워커의 불필요한 대기나 불완전한 데이터로 인한 문제를 줄이려 했습니다.

## 주요 개선 시도 사항

각 워커에서 파이프라인 전체의 성능과 효율성을 향상시키기 위해 다음과 같은 개선을 시도했습니다.

*   **전체 파이프라인 공통:**
    *   **공유 메모리 (Shared Memory - SHM):** 컨테이너 간 대용량 이미지 데이터(NumPy 배열) 전달 시 메모리 직접 참조 방식을 사용하여 IPC 오버헤드를 줄이려 했습니다.
    *   **비동기 처리:** 전체 파이프라인을 비동기 작업 큐 기반으로 설계하여 각 단계가 독립적으로 처리될 수 있도록 했습니다.
    *   **중간 결과 저장 (Redis Hash):** 시간이 소요되는 작업(번역, Inpainting)의 결과를 Redis Hash에 저장하고 후속 작업이 이를 비동기적으로 확인/사용하여 파이프라인 결합도를 낮추고 병렬성을 높이려 했습니다.
    *   **전처리-추론 분리 (신규):** 전처리 작업(디노이징, 리사이징, 패딩)과 추론 작업(LaMa 모델)을 별도 워커로 분리하여 GPU가 추론에 더 집중할 수 있도록 개선을 시도했습니다.
    *   **큐-워커패턴과 컨테이너화:** GPU를 사용하는 OCR과 LaMa 모델 사이의 CUDA 버전 호환성 문제를 해결하기 위해 각각을 컨테이너로 격리했습니다.
    *   **확장성 개선:** 병목이 되는 항목에 대해 워커 개수를 조정할 수 있도록 하여 GPU, CPU 컴퓨팅 자원을 보다 효과적으로 활용하려 했습니다.
    *   **GPU 자원 관리:** OCR과 LaMa Inpainting 모델 간의 GPU 자원 경합 문제가 있었습니다. OCR을 CPU로 이동하는 방안을 검토했으나 성능 저하가 심각하여, 대신 보수적인 batch_limit을 적용하여 안정성을 확보하려 했습니다.

*   **OCR 워커:**
    *   **FP16 연산:** 모델 추론 시 FP16(반정밀도 부동소수점) 연산을 활용하여 연산 속도 개선을 시도했습니다.
    *   **SVTR_LCNet 알고리즘:** 경량화된 모델 구조(LCNet)와 정확도가 개선된 인식 방식(SVTR)을 결합하여 속도와 정확도의 균형을 맞추려 했습니다.
    *   **경량 모델:** PaddleOCR 모델을 사용하여 실시간에 가까운 처리를 시도했습니다.

*   **Processor 워커:**
    *   **마스크 생성 개선:** Inpainting이 불필요한 영역(예: 이미지 배경)은 마스크 생성 과정에서 제외하여 후속 작업의 부하를 줄이려 했습니다.
    *   **비동기 API 호출:** 외부 번역 API 호출 시 비동기 방식을 사용하여 API 응답 대기 시간을 보다 효율적으로 활용하려 했습니다.

*   **Preprocessing 워커 (신규):**
    *   **CPU 디노이징:** Bilateral Filter를 적용하여 인페인팅 품질 향상을 위한 디노이징 작업을 CPU에서 수행하도록 했습니다.
    *   **배치 전처리:** 원본 이미지들을 패딩하고 적절한 크기로 리사이즈하는 작업을 배치 방식으로 수행하여 CPU 활용률을 높이려 했습니다.
    *   **병렬 실행:** GPU 작업(LaMa 추론)과 CPU 작업(전처리)이 병렬로 실행되도록 개선을 시도했습니다.
    *   **디노이징 알고리즘 선정:** 고급 디노이징 기법인 NLM 계열의 알고리즘을 시도했으나 연산 자원과 지연시간 문제로 인해 edge-preserving filter를 선택하여 텍스트 보존과 잡음 제거의 균형을 맞추려 했습니다.

*   **Inpainting 워커 (LaMa):**
    *   **배치 처리 개선:** 전처리가 완료된 이미지들을 즉시 LaMa 모델에 전달하여 GPU 활용률을 높이려 했습니다.
    *   **동적 배치 구성:** 같은 유형(`is_long`, `is_short`)의 작업들만 묶어서 처리하여 배치 내 균일성을 확보하려 했습니다.
    *   **FP16 연산:** LaMa 모델의 주요 연산에 FP16을 적용하여 추론 속도 개선을 시도했습니다.
    *   **부분적 FP32 사용:** 모델의 특정 부분(FFC - Fast Fourier Convolution)이 FP16 연산과 호환성 문제가 있어, 해당 부분만 FP32 연산을 사용하도록 수정하여 안정성을 확보했습니다.

*   **Rendering 워커:**
    *   **텍스트 색상 선택 개선:**
        1.  K-Means 클러스터링을 **원본 이미지** 픽셀의 일부 **랜덤 샘플**에 적용하여 주요 색상 2개를 추출하려 했습니다.
        2.  **Inpainting된 이미지**에서 가장 빈번하게 나타나는 색상(최빈색)을 찾습니다.
        3.  원본 이미지의 주요 색상 2개 중 Inpainting된 이미지의 최빈색이 **아닌** 나머지 색상을 최종 텍스트 색상으로 결정하여 가독성을 개선하려 했습니다.
    *   **K-Means 연산량 감소:** K-Means 연산이 병목이 될 수 있어 랜덤 샘플링을 통해 연산량을 줄이려 했습니다.
    *   **텍스트 크기 계산:** OCR로 인식된 원본 텍스트 바운딩 박스를 벗어나지 않는 범위 내에서 적절한 폰트 크기를 계산하여 적용하려 했습니다.
    *   **번역 길이 조절:** Processor 단계에서 번역 API에 원본 텍스트의 글자 수 정보를 포함하여, 렌더링 시 공간 부족 문제를 줄이려 했습니다.
    *   **비동기 처리:** 렌더링 작업을 비동기로 처리하여 여러 요청을 보다 효율적으로 처리하려 했습니다.

*   **Result Checker 워커:**
    *   **결과 취합 개선:** 번역 결과(`translate_text_result:{request_id}`)와 Inpainting 결과(`inpainting_result:{request_id}`)가 Redis Hash에 저장되는 것을 실시간으로 감지하도록 했습니다.
    *   **적시 렌더링 작업 생성:** 두 결과가 모두 준비되면 즉시 `rendering_tasks` 큐에 작업을 넣어, Rendering 워커의 대기시간을 줄이려 했습니다.

*성능과 최적화 효과는 환경과 데이터에 따라 다를 수 있으며, 지속적인 개선이 필요합니다.

